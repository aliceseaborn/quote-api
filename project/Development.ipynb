{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote API - Engine Documentation\n",
    "\n",
    "Tasks to be completed:\n",
    "1. Pull HTML results from stock query.\n",
    "2. Parse financial information from the HTML results.\n",
    "3. Export information in an organized way.\n",
    "4. Package functions neatly for use in other projects.\n",
    "\n",
    "\n",
    "## <a name=\"TOC\"></a> Table of Contents:\n",
    "---\n",
    "1. [Proof of Concept](#proof)\n",
    "2. [Fundamental Functions](#func)\n",
    "3. [RESTful Functions](#REST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CONFIGURE ENVIRONMENT ------------------------- #\n",
    "\n",
    "# Environment hard reset\n",
    "%reset -f\n",
    "\n",
    "# Libraries for scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import ssl\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# JSON Support\n",
    "import json\n",
    "\n",
    "# Configure paths\n",
    "from pathlib import Path\n",
    "profiles_path = Path('profiles/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"proof\"></a> [Proof of Concept](#TOC)\n",
    "---\n",
    "\n",
    "This section is built to demonstrate how the API could form queries for specific tickers and get the HTML results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading': {'Previous Close': '347.94',\n",
       "  'Open': '348.39',\n",
       "  'Bid': '345.50 x 1000',\n",
       "  'Ask': '344.80 x 800',\n",
       "  'Day Range': '344.10 - 350.60',\n",
       "  'Fifty-Two Week Range': 'Feb 22, 2022',\n",
       "  'Day Volume': '5,342,363',\n",
       "  'Average 3M Volume': '4,210,400'},\n",
       " 'Fundamental': {'Market Capitalization': '362.216B',\n",
       "  'PE Ratio': '23.19',\n",
       "  'EPS Ratio': '14.95',\n",
       "  'Earnings Date': 'Feb 22, 2022',\n",
       "  'Dividend': '6.60',\n",
       "  'Dividend Yield': '1.90',\n",
       "  'Ex Dividend Rate': 'Dec 01, 2021',\n",
       "  'One Year Target Price': '417.23'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- FORM QUERY ------------------------- #\n",
    "\n",
    "ticker = \"HD\"\n",
    "query = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "\n",
    "\n",
    "# ------------------------- PARSE QUERY ------------------------- #\n",
    "\n",
    "# For ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Making the website believe that you are accessing it using a Mozilla browser\n",
    "req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "html = soup.prettify('utf-8')\n",
    "profile = {}\n",
    "trading = {}\n",
    "fundamentals = {}\n",
    "\n",
    "# TRADING\n",
    "\n",
    "# Previous Close\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "    trading['Previous Close'] = td.text.strip()\n",
    "\n",
    "# Open Value\n",
    "for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "    trading['Open'] = td.text.strip()\n",
    "\n",
    "# Bid\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "    trading['Bid'] = td.text.strip()\n",
    "\n",
    "# Ask\n",
    "for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "    trading['Ask'] = td.text.strip()\n",
    "\n",
    "# Day's Range\n",
    "for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "    trading['Day Range'] = td.text.strip()\n",
    "\n",
    "# Fifty-two Week Range\n",
    "for td in soup.findAll('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "    trading['Fifty-Two Week Range'] = span.text.strip()\n",
    "\n",
    "# Trading Volume\n",
    "for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "    trading['Day Volume'] = td.text.strip()\n",
    "\n",
    "# Average 3M Volume\n",
    "for td in soup.findAll('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}):\n",
    "    trading['Average 3M Volume'] = td.text.strip()\n",
    "\n",
    "# FUNDAMENTALS\n",
    "\n",
    "# Market Capitalization\n",
    "for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "    fundamentals['Market Capitalization'] = td.text.strip()\n",
    "\n",
    "# Beta 3Y\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "    fundamentals['Beta 3Y'] = td.text.strip()\n",
    "\n",
    "# PE Ratio\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "    fundamentals['PE Ratio'] = td.text.strip()\n",
    "\n",
    "# EPS Ratio\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "    fundamentals['EPS Ratio'] = td.text.strip()\n",
    "\n",
    "# Earnings Date\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'}):\n",
    "    fundamentals['Earnings Date'] = td.text.strip()\n",
    "\n",
    "# Dividend and Yield\n",
    "for td in soup.findAll('td', attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "    fundamentals['Dividend'] = td.text.strip().split()[0]\n",
    "    fundamentals['Dividend Yield'] = td.text.strip().split()[1].translate({ord(i): None for i in '()%'})\n",
    "\n",
    "# Ex Dividend Date\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "    fundamentals['Ex Dividend Rate'] = td.text.strip()\n",
    "\n",
    "# One Year Target Price\n",
    "for td in soup.findAll('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}):\n",
    "    fundamentals['One Year Target Price'] = td.text.strip()\n",
    "\n",
    "# Other Details\n",
    "profile['Trading'] = trading\n",
    "profile['Fundamental'] = fundamentals\n",
    "\n",
    "# Other Details\n",
    "profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"func\"></a> [Fundamental Functions](#TOC)\n",
    "---\n",
    "\n",
    "Using this experimental code above we can develop functions with better error handling and minimalism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- FORM QUERY ------------------------- #\n",
    "\n",
    "def form_query(ticker):\n",
    "    \"\"\"\n",
    "    Takes a stock ticker as input and returns the full HTTP request\n",
    "    for the yahoo finance query.\n",
    "    \"\"\"\n",
    "    return f\"https://finance.yahoo.com/quote/{ticker}\"\n",
    "\n",
    "\n",
    "# ------------------------- READ HTML ------------------------- #\n",
    "\n",
    "def read_html(query):\n",
    "    \"\"\"\n",
    "    Uses a query and returns the prettified HTML for reading.\n",
    "    \"\"\"\n",
    "    response = requests.get(query)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    print(soup.prettify())\n",
    "\n",
    "\n",
    "# ----------------------- REQUEST WEBPAGE ---------------------- #\n",
    "\n",
    "def request_webpage(query):\n",
    "    \"\"\"\n",
    "    Sends request against Yahoo Finance API using the provided\n",
    "    query. Returns the raw webpage bytes.\n",
    "    \"\"\"\n",
    "\n",
    "    # For ignoring SSL certificate errors\n",
    "    ctx = ssl.create_default_context()\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    # Making the website believe that you are accessing it using a Mozilla browser\n",
    "    req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    return webpage\n",
    "\n",
    "\n",
    "# ------------------------ PARSE WEBPAGE ------------------------ #\n",
    "\n",
    "def parse_webpage(webpage):\n",
    "    \"\"\"\n",
    "    Uses an HTML tree and searches for specific tags which house the\n",
    "    stock information. This function utilizes try-catch methods\n",
    "    for error handling of each data element. Returns empty for the\n",
    "    missing values. The final return is a python dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    profile = {}\n",
    "    trading = {}\n",
    "    fundamentals = {}\n",
    "\n",
    "    # TRADING\n",
    "\n",
    "    # Previous Close\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "        trading['Previous Close'] = td.text.strip()\n",
    "\n",
    "    # Open Value\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "        trading['Open'] = td.text.strip()\n",
    "\n",
    "    # Bid\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "        trading['Bid'] = td.text.strip()\n",
    "\n",
    "    # Ask\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "        trading['Ask'] = td.text.strip()\n",
    "\n",
    "    # Day's Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "        trading['Day Range'] = td.text.strip()\n",
    "\n",
    "    # Fifty-two Week Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "        trading['Fifty-Two Week Range'] = td.text.strip()\n",
    "\n",
    "    # Trading Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "        trading['Day Volume'] = td.text.strip()\n",
    "\n",
    "    # Average 3M Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}):\n",
    "        trading['Average 3M Volume'] = td.text.strip()\n",
    "\n",
    "    # FUNDAMENTALS\n",
    "\n",
    "    # Market Capitalization\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "        fundamentals['Market Capitalization'] = td.text.strip()\n",
    "\n",
    "    # Beta 3Y\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "        fundamentals['Beta 3Y'] = td.text.strip()\n",
    "\n",
    "    # PE Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "        fundamentals['PE Ratio'] = td.text.strip()\n",
    "\n",
    "    # EPS Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "        fundamentals['EPS Ratio'] = td.text.strip()\n",
    "\n",
    "    # Earnings Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'}):\n",
    "        fundamentals['Earnings Date'] = td.text.strip()\n",
    "\n",
    "    # Dividend and Yield\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "        fundamentals['Dividend'] = td.text.strip().split()[0]\n",
    "        fundamentals['Dividend Yield'] = td.text.strip().split()[1].translate({ord(i): None for i in '()%'})\n",
    "\n",
    "    # Ex Dividend Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "        fundamentals['Ex Dividend Rate'] = td.text.strip()\n",
    "\n",
    "    # One Year Target Price\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}):\n",
    "        fundamentals['One Year Target Price'] = td.text.strip()\n",
    "\n",
    "    # Other Details\n",
    "    profile['Trading'] = trading\n",
    "    profile['Fundamental'] = fundamentals\n",
    "\n",
    "    # Other Details\n",
    "    return profile\n",
    "\n",
    "\n",
    "# ----------------------- EXPORT PROFILE ----------------------- #\n",
    "\n",
    "def export_profile(profiles_path, profile, ticker):\n",
    "    \"\"\"\n",
    "    Exports a stock profile into the profiles folder as JSON.\n",
    "    \"\"\"\n",
    "    file = profiles_path / f\"{ticker}.json\"\n",
    "    with file.open(\"w\") as fp:\n",
    "        json.dump(profile, fp)\n",
    "\n",
    "\n",
    "# ----------------------- IMPORT PROFILE ----------------------- #\n",
    "\n",
    "def import_profile(profiles_path, ticker):\n",
    "    \"\"\"\n",
    "    Imports a stock profile from the profiles folder.\n",
    "    \"\"\"\n",
    "    file = profiles_path / f\"{ticker}.json\"\n",
    "    raw = open(file).read()\n",
    "    return json.loads(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading': {'Previous Close': '347.94',\n",
       "  'Open': '348.39',\n",
       "  'Bid': '345.50 x 1000',\n",
       "  'Ask': '344.80 x 800',\n",
       "  'Day Range': '344.10 - 350.60',\n",
       "  'Fifty-Two Week Range': '246.59 - 420.61',\n",
       "  'Day Volume': '5,342,363',\n",
       "  'Average 3M Volume': '4,210,400'},\n",
       " 'Fundamental': {'Market Capitalization': '362.216B',\n",
       "  'PE Ratio': '23.19',\n",
       "  'EPS Ratio': '14.95',\n",
       "  'Earnings Date': 'Feb 22, 2022',\n",
       "  'Dividend': '6.60',\n",
       "  'Dividend Yield': '1.90',\n",
       "  'Ex Dividend Rate': 'Dec 01, 2021',\n",
       "  'One Year Target Price': '417.23'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- TEST FUNCTIONS ------------------------- #\n",
    "\n",
    "# Set test ticker\n",
    "ticker = \"HD\"\n",
    "\n",
    "# Form finance.yahoo query\n",
    "query = form_query(ticker)\n",
    "\n",
    "# Call for profile\n",
    "webpage = request_webpage(query)\n",
    "profile = parse_webpage(webpage)\n",
    "\n",
    "# Export profile as JSON\n",
    "export_profile(profiles_path, profile, ticker)\n",
    "\n",
    "# Return query results\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"REST\"></a> [RESTful Functions](#TOC)\n",
    "---\n",
    "\n",
    "Combining these basic functions together we can form the fundamentals of a REST API: CREATE, UPDATE, GET, DELETE. Some of these functions are redundant. For instance, the CREATE and UPDATE calls are the same as they both prefer to over-write existing information. This is intentional as it ensures that the profile is as up to date as possible but it might not be the best practice for API design as is makes the over-write decision for the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CREATE PROFILE ------------------------- #\n",
    "# Scrapes the information from finance.yahoo and updates the JSON\n",
    "#   stock profile or creates the profile if it did not already exist\n",
    "#   in the database.\n",
    "#\n",
    "\n",
    "def CreateProfile(ticker):\n",
    "    \n",
    "    # Form finance.yahoo query\n",
    "    query = FormQuery(ticker)\n",
    "\n",
    "    # Call for profile\n",
    "    profile = ParseHTML(query)\n",
    "\n",
    "    # Export profile as JSON\n",
    "    ExportJSON(profile, ticker)\n",
    "    \n",
    "    # Return query results\n",
    "    return json.loads(json.dumps(profile))\n",
    "\n",
    "\n",
    "# ------------------------- UPDATE PROFILE ------------------------- #\n",
    "# Creating and updating a profile are ultimately the same function as\n",
    "#   they both overwrite the existing profile or create it if it does\n",
    "#   not exist. For this reason, update calls just function-forward to\n",
    "#   the create call.\n",
    "#\n",
    "\n",
    "def UpdateProfile(ticker):\n",
    "    CreateProfile(ticker)\n",
    "    \n",
    "    \n",
    "# ------------------------- GET PROFILE ------------------------- #\n",
    "# This function finds the profile within the database and loads the\n",
    "#   function as a JSON. In verbose mode, this function will also\n",
    "#   return the dictionary version of the JSON file. In normal mode\n",
    "#   it returns the JSON string itself, assuming an API application.\n",
    "#\n",
    "\n",
    "def GetProfile(ticker):\n",
    "    return ImportJSON(ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading': {'Previous Close': '106.50',\n",
       "  'Open': '107.19',\n",
       "  'Present Value': '106.40',\n",
       "  'Bid': '106.40 x 900',\n",
       "  'Ask': '106.45 x 800',\n",
       "  'Day Volume': '1,545,339',\n",
       "  'Average 3M Volume': '4,671,632',\n",
       "  'Earnings Date': []},\n",
       " 'Fundamental': {'Market Capitalization': '82.119B',\n",
       "  'Beta 3Y': '1.42',\n",
       "  'PE Ratio': '33.64',\n",
       "  'EPS Ratio': '3.16',\n",
       "  'Earnings Date': '20 Nov 2019',\n",
       "  'Dividend': '2.20',\n",
       "  'Dividend Yield': '2.07',\n",
       "  'Ex Dividend Rate': '2019-10-22',\n",
       "  'One Year Target Price': '121.62'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"LOW\"\n",
    "CreateProfile(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Written by Alice Seaborn on 10/08/2019.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
