{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quote API - Engine Documentation\n",
    "\n",
    "Tasks to be completed:\n",
    "1. Pull HTML results from stock query.\n",
    "2. Parse financial information from the HTML results.\n",
    "3. Export information in an organized way.\n",
    "4. Package functions neatly for use in other projects.\n",
    "\n",
    "\n",
    "## <a name=\"TOC\"></a> Table of Contents:\n",
    "---\n",
    "1. [Proof of Concept](#proof)\n",
    "2. [Fundamental Functions](#func)\n",
    "3. [RESTful Functions](#REST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CONFIGURE ENVIRONMENT ------------------------- #\n",
    "\n",
    "# Environment hard reset\n",
    "%reset -f\n",
    "\n",
    "# Libraries for scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import ssl\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# JSON Support\n",
    "import json\n",
    "\n",
    "# Configure paths\n",
    "from pathlib import Path\n",
    "data_path = Path('Profiles/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"proof\"></a> [Proof of Concept](#TOC)\n",
    "---\n",
    "\n",
    "This section is built to demonstrate how the API could form queries for specific tickers and get the HTML results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Present Value': '228.32',\n",
       " 'Other Details': {'Previous Close': '226.67',\n",
       "  'Open': '228.50',\n",
       "  'Bid': '228.24 x 1100',\n",
       "  'Ask': '228.29 x 900',\n",
       "  'Day Volume': '1,155,314',\n",
       "  'Average 3M Volume': '3,752,587',\n",
       "  'Market Capitalization': '250.039B',\n",
       "  'Beta 3Y': '1.14',\n",
       "  'PE Ratio': '22.78',\n",
       "  'EPS Ratio': '10.02',\n",
       "  'Earnings Date': '19 Nov 2019',\n",
       "  'Dividend': '5.44',\n",
       "  'Dividend Yield': '2.41',\n",
       "  'Ex Dividend Rate': '2019-09-04',\n",
       "  'One Year Target Price': '230.85'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- FORM QUERY ------------------------- #\n",
    "\n",
    "ticker = \"HD\"\n",
    "query = \"https://in.finance.yahoo.com/quote/{}?ltr=1\".format(ticker)\n",
    "\n",
    "\n",
    "# ------------------------- PARSE QUERY ------------------------- #\n",
    "\n",
    "# For ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Making the website believe that you are accessing it using a Mozilla browser\n",
    "req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "html = soup.prettify('utf-8')\n",
    "profile = {}\n",
    "details = {}\n",
    "\n",
    "# Present Value\n",
    "for span in soup.findAll('span', attrs={'class': 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'}):\n",
    "    profile['Present Value'] = span.text.strip()\n",
    "\n",
    "# Present Growth\n",
    "for div in soup.findAll('div', attrs={'class': 'D(ib) Va(t)'}):\n",
    "    for span in div.findAll('span', recursive=False):\n",
    "        profile['Present Growth'] = span.text.strip()\n",
    "\n",
    "# Previous Close\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Previous Close'] = span.text.strip()\n",
    "\n",
    "# Open Value\n",
    "for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Open'] = span.text.strip()\n",
    "\n",
    "# Bid\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Bid'] = span.text.strip()\n",
    "\n",
    "# Ask\n",
    "for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Ask'] = span.text.strip()\n",
    "\n",
    "# Day's Range\n",
    "for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Day Range'] = span.text.strip()\n",
    "\n",
    "# Fifty-two Week Range\n",
    "for td in soup.findAll('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Fifty-Two Week Range'] = span.text.strip()\n",
    "\n",
    "# Trading Volume\n",
    "for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Day Volume'] = span.text.strip()\n",
    "\n",
    "# Average 3M Volume\n",
    "for td in soup.findAll('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Average 3M Volume'] = span.text.strip()\n",
    "\n",
    "# Market Capitalization\n",
    "for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Market Capitalization'] = span.text.strip()\n",
    "\n",
    "# Beta 3Y\n",
    "for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Beta 3Y'] = span.text.strip()\n",
    "\n",
    "# PE Ratio\n",
    "for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['PE Ratio'] = span.text.strip()\n",
    "\n",
    "# EPS Ratio\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['EPS Ratio'] = span.text.strip()\n",
    "\n",
    "# Earnings Date\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'}):\n",
    "    details['Earnings Date'] = []\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Earnings Date'] = span.text.strip()\n",
    "\n",
    "# Dividend and Yield\n",
    "for td in soup.findAll('td', attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "    details['Dividend'] = td.text.strip().split()[0]\n",
    "    details['Dividend Yield'] = td.text.strip().split()[1].translate({ord(i): None for i in '()%'})\n",
    "\n",
    "# Ex Dividend Date\n",
    "for td in soup.findAll('td', attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['Ex Dividend Rate'] = span.text.strip()\n",
    "\n",
    "# One Year Target Price\n",
    "for td in soup.findAll('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}):\n",
    "    for span in td.findAll('span', recursive=False):\n",
    "        details['One Year Target Price'] = span.text.strip()\n",
    "\n",
    "# Other Details\n",
    "profile['Other Details'] = details\n",
    "profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"func\"></a> [Fundamental Functions](#TOC)\n",
    "---\n",
    "\n",
    "Using this experimental code above we can develop functions with better error handling and minimalism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- FORM QUERY ------------------------- #\n",
    "# Takes a stock ticker as input and returns the full HTTP request\n",
    "#   for the yahoo finance query. This is an intermediate function\n",
    "#   to streamline other processes.\n",
    "#\n",
    "\n",
    "def FormQuery(ticker):\n",
    "    return \"https://in.finance.yahoo.com/quote/{}?ltr=1\".format(ticker)\n",
    "\n",
    "\n",
    "# ------------------------- READ HTML ------------------------- #\n",
    "# Uses a query and returns the prettified HTML for reading.\n",
    "#\n",
    "\n",
    "def ReadHTML(query):\n",
    "    response = requests.get(query)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    print(soup.prettify())\n",
    "    \n",
    "    \n",
    "# ------------------------- PARSE HTML ------------------------- #\n",
    "# Uses an HTML tree and searches for specific tags which house the\n",
    "#   stock information. This function utilizes try-catch methods\n",
    "#   for error handling of each data element. Returns empty for the\n",
    "#   missing values. The final return is a python dictionary.\n",
    "#\n",
    "\n",
    "def ParseHTML(query):\n",
    "    \n",
    "    # For ignoring SSL certificate errors\n",
    "    ctx = ssl.create_default_context()\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    # Making the website believe that you are accessing it using a Mozilla browser\n",
    "    req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    # Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    html = soup.prettify('utf-8')\n",
    "    profile = {}\n",
    "    trading = {}\n",
    "    fundamentals = {}\n",
    "    \n",
    "    # TRADING\n",
    "    \n",
    "    # Previous Close\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Previous Close'] = span.text.strip()\n",
    "    \n",
    "    # Open Value\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Open'] = span.text.strip()\n",
    "\n",
    "    # Present Value\n",
    "    for span in soup.findAll('span', attrs={'class': 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'}):\n",
    "        trading['Present Value'] = span.text.strip()\n",
    "            \n",
    "    # Bid\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Bid'] = span.text.strip()\n",
    "\n",
    "    # Ask\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Ask'] = span.text.strip()\n",
    "\n",
    "    # Present Growth\n",
    "    for div in soup.findAll('div', attrs={'class': 'D(ib) Va(t)'}):\n",
    "        for span in div.findAll('span', recursive=False):\n",
    "            profile['Present Growth'] = span.text.strip()\n",
    "\n",
    "    # Day's Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Day Range'] = span.text.strip()\n",
    "\n",
    "    # Fifty-two Week Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Fifty-Two Week Range'] = span.text.strip()\n",
    "\n",
    "    # Trading Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Day Volume'] = span.text.strip()\n",
    "\n",
    "    # Average 3M Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Average 3M Volume'] = span.text.strip()\n",
    "            \n",
    "    # FUNDAMENTALS\n",
    "\n",
    "    # Market Capitalization\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Market Capitalization'] = span.text.strip()\n",
    "\n",
    "    # Beta 3Y\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Beta 3Y'] = span.text.strip()\n",
    "\n",
    "    # PE Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['PE Ratio'] = span.text.strip()\n",
    "\n",
    "    # EPS Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['EPS Ratio'] = span.text.strip()\n",
    "\n",
    "    # Earnings Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'}):\n",
    "        trading['Earnings Date'] = []\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Earnings Date'] = span.text.strip()\n",
    "\n",
    "    # Dividend and Yield\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "        fundamentals['Dividend'] = td.text.strip().split()[0]\n",
    "        fundamentals['Dividend Yield'] = td.text.strip().split()[1].translate({ord(i): None for i in '()%'})\n",
    "\n",
    "    # Ex Dividend Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Ex Dividend Rate'] = span.text.strip()\n",
    "\n",
    "    # One Year Target Price\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['One Year Target Price'] = span.text.strip()\n",
    "\n",
    "    # Other Details\n",
    "    profile['Trading'] = trading\n",
    "    profile['Fundamental'] = fundamentals\n",
    "    \n",
    "    # Return full profile\n",
    "    return profile\n",
    "\n",
    "\n",
    "# ------------------------- EXPORT JSON ------------------------- #\n",
    "# Takes the stock profile as a dictionary and exports the contents\n",
    "#   as a JSON file using the ticker as the file name.\n",
    "#\n",
    "\n",
    "def ExportJSON(profile, ticker):\n",
    "    data_file = data_path / \"{}.json\".format(ticker)\n",
    "    with data_file.open(\"w\") as fp:\n",
    "        json.dump(profile, fp)\n",
    "\n",
    "\n",
    "# ------------------------- IMPORT JSON ------------------------- #\n",
    "# Takes a stock ticker and finds the stock profile JSON before\n",
    "#   returning the contents of the profile as a dictionary.\n",
    "#\n",
    "\n",
    "def ImportJSON(ticker):\n",
    "    data_file = data_path / \"{}.json\".format(ticker)\n",
    "    data_str = open(data_file).read()\n",
    "    return json.loads(data_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading': {'Previous Close': '91.99',\n",
       "  'Open': '93.19',\n",
       "  'Present Value': '93.22',\n",
       "  'Bid': '93.29 x 1100',\n",
       "  'Ask': '93.42 x 1100',\n",
       "  'Day Volume': '230,907',\n",
       "  'Average 3M Volume': '845,490',\n",
       "  'Earnings Date': []},\n",
       " 'Fundamental': {'Market Capitalization': '13.558B',\n",
       "  'Beta 3Y': '1.73',\n",
       "  'PE Ratio': '22.81',\n",
       "  'EPS Ratio': '4.09',\n",
       "  'Earnings Date': '21 Oct 2019',\n",
       "  'Dividend': '1.96',\n",
       "  'Dividend Yield': '2.13',\n",
       "  'Ex Dividend Rate': '2019-08-29',\n",
       "  'One Year Target Price': '107.64'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- TEST FUNCTIONS ------------------------- #\n",
    "\n",
    "# Set ticker and form query\n",
    "ticker = \"DOV\"\n",
    "query = FormQuery(ticker)\n",
    "\n",
    "# Call for profile\n",
    "profile = ParseHTML(query)\n",
    "\n",
    "# Export profile as JSON\n",
    "ExportJSON(profile, ticker)\n",
    "\n",
    "# Import profile from JSON for inspection\n",
    "ImportJSON(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"REST\"></a> [RESTful Functions](#TOC)\n",
    "---\n",
    "\n",
    "Combining these basic functions together we can form the fundamentals of a REST API: CREATE, UPDATE, GET, DELETE. Some of these functions are redundant. For instance, the CREATE and UPDATE calls are the same as they both prefer to over-write existing information. This is intentional as it ensures that the profile is as up to date as possible but it might not be the best practice for API design as is makes the over-write decision for the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CREATE PROFILE ------------------------- #\n",
    "# Scrapes the information from finance.yahoo and updates the JSON\n",
    "#   stock profile or creates the profile if it did not already exist\n",
    "#   in the database.\n",
    "#\n",
    "\n",
    "def CreateProfile(ticker):\n",
    "    \n",
    "    # Form finance.yahoo query\n",
    "    query = FormQuery(ticker)\n",
    "\n",
    "    # Call for profile\n",
    "    profile = ParseHTML(query)\n",
    "\n",
    "    # Export profile as JSON\n",
    "    ExportJSON(profile, ticker)\n",
    "    \n",
    "    # Return query results\n",
    "    return json.loads(json.dumps(profile))\n",
    "\n",
    "\n",
    "# ------------------------- UPDATE PROFILE ------------------------- #\n",
    "# Creating and updating a profile are ultimately the same function as\n",
    "#   they both overwrite the existing profile or create it if it does\n",
    "#   not exist. For this reason, update calls just function-forward to\n",
    "#   the create call.\n",
    "#\n",
    "\n",
    "def UpdateProfile(ticker):\n",
    "    CreateProfile(ticker)\n",
    "    \n",
    "    \n",
    "# ------------------------- GET PROFILE ------------------------- #\n",
    "# This function finds the profile within the database and loads the\n",
    "#   function as a JSON. In verbose mode, this function will also\n",
    "#   return the dictionary version of the JSON file. In normal mode\n",
    "#   it returns the JSON string itself, assuming an API application.\n",
    "#\n",
    "\n",
    "def GetProfile(ticker):\n",
    "    return ImportJSON(ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trading': {'Previous Close': '106.50',\n",
       "  'Open': '107.19',\n",
       "  'Present Value': '106.40',\n",
       "  'Bid': '106.40 x 900',\n",
       "  'Ask': '106.45 x 800',\n",
       "  'Day Volume': '1,545,339',\n",
       "  'Average 3M Volume': '4,671,632',\n",
       "  'Earnings Date': []},\n",
       " 'Fundamental': {'Market Capitalization': '82.119B',\n",
       "  'Beta 3Y': '1.42',\n",
       "  'PE Ratio': '33.64',\n",
       "  'EPS Ratio': '3.16',\n",
       "  'Earnings Date': '20 Nov 2019',\n",
       "  'Dividend': '2.20',\n",
       "  'Dividend Yield': '2.07',\n",
       "  'Ex Dividend Rate': '2019-10-22',\n",
       "  'One Year Target Price': '121.62'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"LOW\"\n",
    "CreateProfile(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Written by Austin Dial on 10/08/2019.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
